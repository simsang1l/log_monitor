input {
  file {
    path => "/data/SSH.log"           # 실제 로그 파일 경로
    start_position => "beginning" # "end"          # 처음에는 파일 끝에서부터(실시간만)
    sincedb_path => "/dev/null" # "/usr/share/logstash/data/ssh.sincedb"  # 읽은 위치 저장
    mode => "tail"
    # ignore_older => 0               # (옵션) 오래된 파일도 계속 감시
  }
}

filter {
  grok {
    match => { "message" => "%{SYSLOGTIMESTAMP:logdate} %{HOSTNAME:host} %{DATA:process}(?:\[%{NUMBER:pid}\])?: %{GREEDYDATA:msg}" }
  }
  date {
    match => [ "logdate", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
    target => "@timestamp"
  }

  # 원하는 날짜만 통과시키는 조건 (예: 7월 15일만)
  if !("Dec 10" in [logdate]) {
    drop { }
  }
}

output {
#   stdout { codec => rubydebug }
  kafka {
    bootstrap_servers => "kafka:29092"
    topic_id => "ssh-log"
    codec => json
    acks => "all"
    # key_serializer => "org.apache.kafka.common.serialization.StringSerializer"
  }
}