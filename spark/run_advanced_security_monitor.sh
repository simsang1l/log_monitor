#!/bin/bash

# ê³ ê¸‰ ë³´ì•ˆ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

echo "ğŸš€ ê³ ê¸‰ ë³´ì•ˆ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì„ ì‹œì‘í•©ë‹ˆë‹¤..."

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export BRUTE_FORCE_THRESHOLD=5
export DDOS_THRESHOLD=100
export SUSPICIOUS_USER_THRESHOLD=10
export TIME_WINDOW_MINUTES=10
export SLIDE_INTERVAL_MINUTES=5
export ALERT_COOLDOWN_MINUTES=30

# Elasticsearch ì„¤ì •
export ES_HOST=elasticsearch
export ES_PORT=9200
export ES_USERNAME=elastic
export ES_PASSWORD=changeme

# Kafka ì„¤ì •
export KAFKA_BOOTSTRAP_SERVERS=kafka1:29092,kafka2:29093,kafka3:29094

# ì•Œë¦¼ ì„¤ì •
export CRITICAL_COOLDOWN_MINUTES=5
export HIGH_COOLDOWN_MINUTES=15
export MEDIUM_COOLDOWN_MINUTES=30

echo "ğŸ“Š ì„¤ì •ê°’:"
echo "  - Brute Force ì„ê³„ê°’: ${BRUTE_FORCE_THRESHOLD}íšŒ"
echo "  - DDoS ì„ê³„ê°’: ${DDOS_THRESHOLD}íšŒ"
echo "  - ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì‚¬ìš©ì ì„ê³„ê°’: ${SUSPICIOUS_USER_THRESHOLD}íšŒ"
echo "  - ì‹œê°„ ìœˆë„ìš°: ${TIME_WINDOW_MINUTES}ë¶„"
echo "  - ìŠ¬ë¼ì´ë“œ ê°„ê²©: ${SLIDE_INTERVAL_MINUTES}ë¶„"

# Spark ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
echo "ğŸ” Spark Streaming ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤..."

spark-submit \
    --master spark://spark-master:7077 \
    --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0,org.elasticsearch:elasticsearch-hadoop:8.8.0 \
    --conf "spark.sql.adaptive.enabled=true" \
    --conf "spark.sql.adaptive.coalescePartitions.enabled=true" \
    --conf "spark.sql.adaptive.skewJoin.enabled=true" \
    --conf "spark.sql.adaptive.localShuffleReader.enabled=true" \
    --conf "spark.sql.shuffle.partitions=2" \
    --conf "spark.default.parallelism=2" \
    --conf "spark.sql.adaptive.advisoryPartitionSizeInBytes=32MB" \
    --conf "spark.sql.adaptive.coalescePartitions.minPartitionNum=1" \
    --conf "spark.sql.adaptive.coalescePartitions.initialPartitionNum=1" \
    --conf "spark.sql.streaming.statefulOperator.checkCorrectness.enabled=false" \
    --conf "spark.sql.streaming.unsupportedOperationCheck.enabled=false" \
    --conf "spark.sql.adaptive.autoBroadcastJoinThreshold=10MB" \
    --conf "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes=256MB" \
    --conf "spark.sql.adaptive.skewJoin.skewedPartitionFactor=5" \
    --conf "spark.sql.adaptive.coalescePartitions.parallelismFirst=false" \
    --conf "spark.sql.adaptive.coalescePartitions.minPartitionSize=1MB" \
    --conf "spark.executor.memory=1g" \
    --conf "spark.driver.memory=1g" \
    --conf "spark.executor.cores=1" \
    --conf "spark.driver.cores=1" \
    --conf "spark.sql.streaming.checkpointLocation=/tmp/checkpoint/advanced-security-monitor" \
    /opt/bitnami/spark/work/advanced_security_monitor.py

echo "âœ… ê³ ê¸‰ ë³´ì•ˆ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤." 